{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_text_generator_00.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEZEYhXCzaOY4YC7IIdsvh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8xB0z_hYbG",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow 2.0 Text generator on Dante Alighieri's Divine Comedy\n",
        "\n",
        "Author: **Ivan Bongiorni**, [LinkedIn profile](https://www.linkedin.com/in/ivan-bongiorni-b8a583164/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncDUryHdqckI",
        "colab_type": "text"
      },
      "source": [
        "This Notebook contains a **text generator RNN** that was trained on the **Divina Commedia** (the *Divine Comedy*) by **Dante Alighieri**. This is a poem written at the beginning of the XII century. It's hard to explain what it represents for Italian culture: it's without any doubt the main pillar of our national literature, one of the building blocks of modern Italian language, and arguably the gratest poem ever. All modern representations of Hell, Purgatory and Heaven derive from this opera.\n",
        "\n",
        "It's structure is extremely interesting: each verse is composed of 11 syllables, and its rhymes follow an **A-B-A-B** structure. Lot of pattern to be learned! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8FnhxiWY_Y1",
        "colab_type": "code",
        "outputId": "948d53c3-e0b1-4d73-e526-dadd425092d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import time\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Read file from Colab Notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5YiWU0daYkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_path = \" [...] /TF_2.0/NLP/text_generator/\"\n",
        "\n",
        "# Read the Divina Commedia\n",
        "with open(current_path + \"DivinaCommedia.txt\", 'r', encoding=\"utf8\") as file:\n",
        "    divina_commedia = file.read()\n",
        "\n",
        "# Replace rare characters\n",
        "divina_commedia = divina_commedia.replace(\"ä\", \"a\")\n",
        "divina_commedia = divina_commedia.replace(\"é\", \"è\")\n",
        "divina_commedia = divina_commedia.replace(\"ë\", \"è\")\n",
        "divina_commedia = divina_commedia.replace(\"Ë\", \"E\")\n",
        "divina_commedia = divina_commedia.replace(\"ï\", \"i\")\n",
        "divina_commedia = divina_commedia.replace(\"Ï\", \"I\")\n",
        "divina_commedia = divina_commedia.replace(\"ó\", \"ò\")\n",
        "divina_commedia = divina_commedia.replace(\"ö\", \"o\")\n",
        "divina_commedia = divina_commedia.replace(\"ü\", \"u\")\n",
        "\n",
        "divina_commedia = divina_commedia.replace(\"(\", \"-\")\n",
        "divina_commedia = divina_commedia.replace(\")\", \"-\")\n",
        "divina_commedia = divina_commedia.replace(\"[\", \"\")\n",
        "divina_commedia = divina_commedia.replace(\"]\", \"\")\n",
        "\n",
        "divina_commedia = re.sub(r'[0-9]+', '', divina_commedia)\n",
        "divina_commedia = divina_commedia.replace(\" \\n\", \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILphRXIXaYrP",
        "colab_type": "code",
        "outputId": "108f777a-2f35-4b90-a086-42b326022d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check lenght of text\n",
        "print(len(divina_commedia))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "551697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZw3-Joyhg5l",
        "colab_type": "text"
      },
      "source": [
        "I will now extract the set of unique characters, and create a dictionary for vectorization of text. In order to feed the text into a Neural Network, I must turn each character into a number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwvjeLGWAVE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store unique characters into a dict with numerical encoding\n",
        "unique_chars = list(set(divina_commedia))\n",
        "unique_chars.sort()  # to make sure you get the same encoding at each run\n",
        "\n",
        "# Store them in a dict, associated with a numerical index\n",
        "char2idx = { char[1]: char[0] for char in enumerate(unique_chars) }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkXOJ3LGAVCF",
        "colab_type": "code",
        "outputId": "b020a397-eafb-4b39-9f76-1d361abd3fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(char2idx))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sieJxDhAU_V",
        "colab_type": "code",
        "outputId": "79310734-7f0f-4e6c-c773-258a5358ed9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "char2idx"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " \"'\": 4,\n",
              " ',': 5,\n",
              " '-': 6,\n",
              " '.': 7,\n",
              " ':': 8,\n",
              " ';': 9,\n",
              " '?': 10,\n",
              " 'A': 11,\n",
              " 'B': 12,\n",
              " 'C': 13,\n",
              " 'D': 14,\n",
              " 'E': 15,\n",
              " 'F': 16,\n",
              " 'G': 17,\n",
              " 'H': 18,\n",
              " 'I': 19,\n",
              " 'L': 20,\n",
              " 'M': 21,\n",
              " 'N': 22,\n",
              " 'O': 23,\n",
              " 'P': 24,\n",
              " 'Q': 25,\n",
              " 'R': 26,\n",
              " 'S': 27,\n",
              " 'T': 28,\n",
              " 'U': 29,\n",
              " 'V': 30,\n",
              " 'X': 31,\n",
              " 'Z': 32,\n",
              " 'a': 33,\n",
              " 'b': 34,\n",
              " 'c': 35,\n",
              " 'd': 36,\n",
              " 'e': 37,\n",
              " 'f': 38,\n",
              " 'g': 39,\n",
              " 'h': 40,\n",
              " 'i': 41,\n",
              " 'j': 42,\n",
              " 'l': 43,\n",
              " 'm': 44,\n",
              " 'n': 45,\n",
              " 'o': 46,\n",
              " 'p': 47,\n",
              " 'q': 48,\n",
              " 'r': 49,\n",
              " 's': 50,\n",
              " 't': 51,\n",
              " 'u': 52,\n",
              " 'v': 53,\n",
              " 'x': 54,\n",
              " 'y': 55,\n",
              " 'z': 56,\n",
              " 'È': 57,\n",
              " 'à': 58,\n",
              " 'è': 59,\n",
              " 'ì': 60,\n",
              " 'ò': 61,\n",
              " 'ù': 62}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2H5G86HhyvE",
        "colab_type": "text"
      },
      "source": [
        "Once I have a dictionary that maps each characted with its respective numerical index, I can process the whole corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk_BqFK4AU9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_encoding(text, char_dict):\n",
        "    \"\"\" Text to list of chars, to np.array of numerical idx \"\"\"\n",
        "    chars_list = [ char for char in text ]\n",
        "    chars_list = [ char_dict[char] for char in chars_list ]\n",
        "    chars_list = np.array(chars_list)\n",
        "    return chars_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7JpYN9LAU7U",
        "colab_type": "code",
        "outputId": "79f714c0-a0a6-495f-e900-c39d3b329b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Let's see what the first line will look like\n",
        "print(\"{}\".format(divina_commedia[276:311]))\n",
        "print(\"\\nbecomes:\")\n",
        "print(numerical_encoding(divina_commedia[276:311], char2idx))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nel mezzo del cammin di nostra vita\n",
            "\n",
            "becomes:\n",
            "[22 37 43  1 44 37 56 56 46  1 36 37 43  1 35 33 44 44 41 45  1 36 41  1\n",
            " 45 46 50 51 49 33  1 53 41 51 33]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqALeTUmnl0X",
        "colab_type": "text"
      },
      "source": [
        "## RNN dataprep\n",
        "\n",
        "I need to generate a set of stacked input sequences. My goal is to train a Neural Network to find a mapping between an input sequence and an output sequence of equal length, in which each character is shifted left of one position.\n",
        "\n",
        "For example, the first verse:\n",
        "\n",
        "> Nel mezzo del cammin di nostra vita\n",
        "\n",
        "would be translated in a train sequence as:\n",
        "\n",
        "`Nel mezzo del cammin di nostra vit`\n",
        "\n",
        "be associated with the target sequence:\n",
        "\n",
        "`el mezzo del cammin di nostra vita`\n",
        "\n",
        "The following function is a preparatory step for that. More generally, given a sequence:\n",
        "\n",
        "```\n",
        "A B C D E F G H I\n",
        "```\n",
        "\n",
        "and assuming input sequences of length 5, it will generate a matrix like:\n",
        "\n",
        "```\n",
        "A B C D E\n",
        "B C D E F\n",
        "C D E F G\n",
        "D E F G H\n",
        "E F G H I\n",
        "```\n",
        "\n",
        "I will save that matrix as it is in .csv format, to use it to train the Language Generator later.\n",
        "The split between train and target sets will be as:\n",
        "\n",
        "```\n",
        " Train:           Target:\n",
        "                 \n",
        "A B C D E        B C D E F\n",
        "B C D E F        C D E F G\n",
        "C D E F G        D E F G H\n",
        "D E F G H        E F G H I\n",
        "                 \n",
        "```\n",
        "\n",
        "Train and target sets are fundamentally the same matrix, with the train having the last row removed, and the target set having the first removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWcZzOJdG6X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply it on the whole Comedy\n",
        "encoded_text = numerical_encoding(divina_commedia, char2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t41gYByxAU4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_text_matrix(sequence, len_input):\n",
        "    \n",
        "    # create empty matrix\n",
        "    X = np.empty((len(sequence)-len_input, len_input))\n",
        "    \n",
        "    # fill each row/time window from input sequence\n",
        "    for i in range(X.shape[0]):\n",
        "        X[i,:] = sequence[i : i+len_input]\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eazAAQiAk0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_matrix = get_text_matrix(encoded_text, 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KonviQjQAk40",
        "colab_type": "code",
        "outputId": "3d20f758-3088-4645-9aa3-3ee3d4f40823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(text_matrix.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(551597, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaVngDG7AkyU",
        "colab_type": "code",
        "outputId": "730a7be7-daf2-4eb7-f536-9e281cbc662f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "print(\"100th train sequence:\\n\")\n",
        "print(text_matrix[ 100, : ])\n",
        "print(\"\\n\\n100th target sequence:\\n\")\n",
        "print(text_matrix[ 101, : ])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100th train sequence:\n",
            "\n",
            "[45. 37.  1. 37.  1. 47. 52. 45. 41. 44. 37. 45. 51. 41.  1. 36. 37.  4.\n",
            "  1. 53. 41. 56. 41.  1. 37.  1. 36. 37.  4.  1. 44. 37. 49. 41. 51. 41.\n",
            "  1. 37.  1. 47. 49. 37. 44. 41.  1. 36. 37.  1. 43. 37.  1. 53. 41. 49.\n",
            " 51. 62.  7.  1. 13. 46. 44. 41. 45. 35. 41. 33.  1. 41. 43.  1. 35. 33.\n",
            " 45. 51. 46.  1. 47. 49. 41. 44. 46.  1. 36. 37.  1. 43. 33.  1. 47. 49.\n",
            " 41. 44. 33.  1. 47. 33. 49. 51. 37.  1.]\n",
            "\n",
            "\n",
            "100th target sequence:\n",
            "\n",
            "[37.  1. 37.  1. 47. 52. 45. 41. 44. 37. 45. 51. 41.  1. 36. 37.  4.  1.\n",
            " 53. 41. 56. 41.  1. 37.  1. 36. 37.  4.  1. 44. 37. 49. 41. 51. 41.  1.\n",
            " 37.  1. 47. 49. 37. 44. 41.  1. 36. 37.  1. 43. 37.  1. 53. 41. 49. 51.\n",
            " 62.  7.  1. 13. 46. 44. 41. 45. 35. 41. 33.  1. 41. 43.  1. 35. 33. 45.\n",
            " 51. 46.  1. 47. 49. 41. 44. 46.  1. 36. 37.  1. 43. 33.  1. 47. 49. 41.\n",
            " 44. 33.  1. 47. 33. 49. 51. 37.  1. 43.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPjMSZOzh_60",
        "colab_type": "text"
      },
      "source": [
        "# Architecture\n",
        "\n",
        "At this point, I can specify the RNN architecture with all its hyperparameters. An `Embedding()` layer will first learn a representation of each character; the sequence of chracters embedding will then be fed into an `LSTM()` layer, that will extract information from their sequence; `Dense()` layers at the end will produce the next character prediction.\n",
        "\n",
        "The Network is structured to be fed with batches of data of fixed size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFZfbimYAkvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# size of vocabulary\n",
        "vocab_size = len(char2idx)\n",
        "\n",
        "# size of mini batches during training\n",
        "batch_size = 100\n",
        "\n",
        "# size of training subset at each epoch\n",
        "subset_size = batch_size * 100\n",
        "\n",
        "# vector size of char embeddings\n",
        "embedding_size = 250\n",
        "\n",
        "len_input = 1000   # 200\n",
        "\n",
        "hidden_size = 250  # for Dense() layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1JqO7rhAktC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.activations import elu, relu, softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKysyBfpAtUS",
        "colab_type": "code",
        "outputId": "6d987cb1-40ee-4896-8b41-d52ae0cf70a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "RNN = Sequential([\n",
        "    Embedding(vocab_size, embedding_size,\n",
        "              batch_input_shape=(batch_size, None)),\n",
        "    \n",
        "    LSTM(len_input, return_sequences = True),\n",
        "    \n",
        "    Dense(hidden_size, activation = relu), \n",
        "    \n",
        "    Dense(vocab_size)\n",
        "])\n",
        "\n",
        "RNN.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (100, None, 250)          15750     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (100, None, 1000)         5004000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (100, None, 250)          250250    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (100, None, 63)           15813     \n",
            "=================================================================\n",
            "Total params: 5,285,813\n",
            "Trainable params: 5,285,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9Tldq4qAtXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUgGeC5ZAtbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is an Autograph function\n",
        "# its decorator makes it a TF op - i.e. much faster\n",
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = tf.reduce_mean(\n",
        "            tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                y, RNN(x), from_logits = True))\n",
        "    gradients = tape.gradient(current_loss, RNN.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, RNN.trainable_variables))\n",
        "    return current_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-x5RxKrAtnR",
        "colab_type": "code",
        "outputId": "526b30d3-af50-4cc4-8356-7c22ea15c7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loss_history = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start = time.time()\n",
        "    \n",
        "    # Take subsets of train and target\n",
        "    sample = np.random.randint(0, text_matrix.shape[0]-1, subset_size)\n",
        "    sample_train = text_matrix[ sample , : ]\n",
        "    sample_target = text_matrix[ sample+1 , : ]\n",
        "    \n",
        "    for iteration in range(sample_train.shape[0] // batch_size):\n",
        "        take = iteration * batch_size\n",
        "        x = sample_train[ take:take+batch_size , : ]\n",
        "        y = sample_target[ take:take+batch_size , : ]\n",
        "\n",
        "        current_loss = train_on_batch(x, y)\n",
        "        loss_history.append(current_loss)\n",
        "    \n",
        "    print(\"{}.  \\t  Loss: {}  \\t  Time: {}ss\".format(\n",
        "        epoch+1, current_loss.numpy(), round(time.time()-start, 2)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.  \t  Loss: 3.072500705718994  \t  Time: 14.92ss\n",
            "2.  \t  Loss: 2.957970142364502  \t  Time: 7.59ss\n",
            "3.  \t  Loss: 2.577200412750244  \t  Time: 7.58ss\n",
            "4.  \t  Loss: 2.415374517440796  \t  Time: 7.59ss\n",
            "5.  \t  Loss: 2.3381526470184326  \t  Time: 7.59ss\n",
            "6.  \t  Loss: 2.260857343673706  \t  Time: 7.58ss\n",
            "7.  \t  Loss: 2.2402889728546143  \t  Time: 7.58ss\n",
            "8.  \t  Loss: 2.1702616214752197  \t  Time: 7.59ss\n",
            "9.  \t  Loss: 2.137619733810425  \t  Time: 7.58ss\n",
            "10.  \t  Loss: 2.1122875213623047  \t  Time: 7.6ss\n",
            "11.  \t  Loss: 2.0589234828948975  \t  Time: 7.59ss\n",
            "12.  \t  Loss: 2.056528091430664  \t  Time: 7.59ss\n",
            "13.  \t  Loss: 2.027541399002075  \t  Time: 7.59ss\n",
            "14.  \t  Loss: 2.005847454071045  \t  Time: 7.59ss\n",
            "15.  \t  Loss: 2.0110795497894287  \t  Time: 7.63ss\n",
            "16.  \t  Loss: 1.9466191530227661  \t  Time: 7.58ss\n",
            "17.  \t  Loss: 1.9405425786972046  \t  Time: 7.58ss\n",
            "18.  \t  Loss: 1.9408313035964966  \t  Time: 7.57ss\n",
            "19.  \t  Loss: 1.9250353574752808  \t  Time: 7.58ss\n",
            "20.  \t  Loss: 1.8843433856964111  \t  Time: 7.57ss\n",
            "21.  \t  Loss: 1.8922566175460815  \t  Time: 7.56ss\n",
            "22.  \t  Loss: 1.9076796770095825  \t  Time: 7.59ss\n",
            "23.  \t  Loss: 1.8852293491363525  \t  Time: 7.57ss\n",
            "24.  \t  Loss: 1.8748210668563843  \t  Time: 7.58ss\n",
            "25.  \t  Loss: 1.8662488460540771  \t  Time: 7.56ss\n",
            "26.  \t  Loss: 1.7994751930236816  \t  Time: 7.58ss\n",
            "27.  \t  Loss: 1.8747007846832275  \t  Time: 7.6ss\n",
            "28.  \t  Loss: 1.823426604270935  \t  Time: 7.58ss\n",
            "29.  \t  Loss: 1.8228120803833008  \t  Time: 7.57ss\n",
            "30.  \t  Loss: 1.789873480796814  \t  Time: 7.58ss\n",
            "31.  \t  Loss: 1.7624784708023071  \t  Time: 7.57ss\n",
            "32.  \t  Loss: 1.7963734865188599  \t  Time: 7.57ss\n",
            "33.  \t  Loss: 1.7762773036956787  \t  Time: 7.56ss\n",
            "34.  \t  Loss: 1.7459098100662231  \t  Time: 7.6ss\n",
            "35.  \t  Loss: 1.75569486618042  \t  Time: 7.59ss\n",
            "36.  \t  Loss: 1.7706636190414429  \t  Time: 7.58ss\n",
            "37.  \t  Loss: 1.7370904684066772  \t  Time: 7.57ss\n",
            "38.  \t  Loss: 1.7198837995529175  \t  Time: 7.57ss\n",
            "39.  \t  Loss: 1.7358664274215698  \t  Time: 7.59ss\n",
            "40.  \t  Loss: 1.6769226789474487  \t  Time: 7.57ss\n",
            "41.  \t  Loss: 1.7079578638076782  \t  Time: 7.57ss\n",
            "42.  \t  Loss: 1.7010931968688965  \t  Time: 7.57ss\n",
            "43.  \t  Loss: 1.7068103551864624  \t  Time: 7.57ss\n",
            "44.  \t  Loss: 1.6513859033584595  \t  Time: 7.57ss\n",
            "45.  \t  Loss: 1.687230110168457  \t  Time: 7.57ss\n",
            "46.  \t  Loss: 1.6650090217590332  \t  Time: 7.58ss\n",
            "47.  \t  Loss: 1.6460039615631104  \t  Time: 7.6ss\n",
            "48.  \t  Loss: 1.614156723022461  \t  Time: 7.6ss\n",
            "49.  \t  Loss: 1.607173204421997  \t  Time: 7.58ss\n",
            "50.  \t  Loss: 1.625852346420288  \t  Time: 7.57ss\n",
            "51.  \t  Loss: 1.6108134984970093  \t  Time: 7.57ss\n",
            "52.  \t  Loss: 1.6237413883209229  \t  Time: 7.57ss\n",
            "53.  \t  Loss: 1.5856447219848633  \t  Time: 7.58ss\n",
            "54.  \t  Loss: 1.616779088973999  \t  Time: 7.58ss\n",
            "55.  \t  Loss: 1.5694152116775513  \t  Time: 7.6ss\n",
            "56.  \t  Loss: 1.5844537019729614  \t  Time: 7.61ss\n",
            "57.  \t  Loss: 1.5838656425476074  \t  Time: 7.6ss\n",
            "58.  \t  Loss: 1.5657349824905396  \t  Time: 7.59ss\n",
            "59.  \t  Loss: 1.5648351907730103  \t  Time: 7.57ss\n",
            "60.  \t  Loss: 1.5778411626815796  \t  Time: 7.57ss\n",
            "61.  \t  Loss: 1.5735400915145874  \t  Time: 7.58ss\n",
            "62.  \t  Loss: 1.5776091814041138  \t  Time: 7.59ss\n",
            "63.  \t  Loss: 1.5240793228149414  \t  Time: 7.58ss\n",
            "64.  \t  Loss: 1.527056097984314  \t  Time: 7.58ss\n",
            "65.  \t  Loss: 1.5307105779647827  \t  Time: 7.59ss\n",
            "66.  \t  Loss: 1.5254395008087158  \t  Time: 7.59ss\n",
            "67.  \t  Loss: 1.5316236019134521  \t  Time: 7.6ss\n",
            "68.  \t  Loss: 1.517667531967163  \t  Time: 7.57ss\n",
            "69.  \t  Loss: 1.5019526481628418  \t  Time: 7.58ss\n",
            "70.  \t  Loss: 1.4704419374465942  \t  Time: 7.57ss\n",
            "71.  \t  Loss: 1.489258885383606  \t  Time: 7.58ss\n",
            "72.  \t  Loss: 1.5058043003082275  \t  Time: 7.57ss\n",
            "73.  \t  Loss: 1.5096497535705566  \t  Time: 7.56ss\n",
            "74.  \t  Loss: 1.4681944847106934  \t  Time: 7.59ss\n",
            "75.  \t  Loss: 1.4726403951644897  \t  Time: 7.57ss\n",
            "76.  \t  Loss: 1.4658737182617188  \t  Time: 7.56ss\n",
            "77.  \t  Loss: 1.4032140970230103  \t  Time: 7.57ss\n",
            "78.  \t  Loss: 1.4850512742996216  \t  Time: 7.56ss\n",
            "79.  \t  Loss: 1.4615461826324463  \t  Time: 7.58ss\n",
            "80.  \t  Loss: 1.4805454015731812  \t  Time: 7.57ss\n",
            "81.  \t  Loss: 1.4137877225875854  \t  Time: 7.57ss\n",
            "82.  \t  Loss: 1.4438412189483643  \t  Time: 7.59ss\n",
            "83.  \t  Loss: 1.450463056564331  \t  Time: 7.56ss\n",
            "84.  \t  Loss: 1.4167364835739136  \t  Time: 7.59ss\n",
            "85.  \t  Loss: 1.4113616943359375  \t  Time: 7.57ss\n",
            "86.  \t  Loss: 1.407659649848938  \t  Time: 7.57ss\n",
            "87.  \t  Loss: 1.4095017910003662  \t  Time: 7.57ss\n",
            "88.  \t  Loss: 1.3954694271087646  \t  Time: 7.57ss\n",
            "89.  \t  Loss: 1.3892732858657837  \t  Time: 7.56ss\n",
            "90.  \t  Loss: 1.4305318593978882  \t  Time: 7.57ss\n",
            "91.  \t  Loss: 1.3660508394241333  \t  Time: 7.57ss\n",
            "92.  \t  Loss: 1.4043421745300293  \t  Time: 7.56ss\n",
            "93.  \t  Loss: 1.3494398593902588  \t  Time: 7.57ss\n",
            "94.  \t  Loss: 1.3862204551696777  \t  Time: 7.57ss\n",
            "95.  \t  Loss: 1.3671904802322388  \t  Time: 7.58ss\n",
            "96.  \t  Loss: 1.360722541809082  \t  Time: 7.59ss\n",
            "97.  \t  Loss: 1.3654136657714844  \t  Time: 7.61ss\n",
            "98.  \t  Loss: 1.3310920000076294  \t  Time: 7.57ss\n",
            "99.  \t  Loss: 1.3655935525894165  \t  Time: 7.55ss\n",
            "100.  \t  Loss: 1.348952293395996  \t  Time: 7.57ss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6uAhmV2Atth",
        "colab_type": "code",
        "outputId": "407b71d5-18bf-49e9-ec14-1ecf8def79b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(loss_history)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd5xV9Z3/8dfn3qn0NiBNBwE1WBEW\nOxILEGxxo7uua+w/TfaXskY0aKJGY1zTNLquG43GqGnE8ogGsStgRQcFBCnSOwxthmGY/tk/7mGc\n3piZM+fO+/l43IenfO89nzMH33Pme773HHN3REQk+mJhFyAiIq1DgS4ikiQU6CIiSUKBLiKSJBTo\nIiJJQoEuIpIkFOiSFMwsbmYFZnZwa7YViRLTOHQJg5kVVJntAhQD5cH89e7+p/av6sCZ2d3AEHe/\nMuxapPNJCbsA6Zzcvdv+aTNbA1zr7m/U197MUty9rD1qE4kqdblIh2Rmd5vZdDP7i5ntAS4zs5PM\n7EMz221mm83sQTNLDdqnmJmbWXYw/8dg/ctmtsfMPjCzYc1tG6z/mpktN7M8M/tvM3vPzK5swT4d\naWazg/o/M7Nzqqw718yWBNvfYGY3BMv7m9nM4D07zWxOS3+mkvwU6NKRXQj8GegJTAfKgO8D/YBT\ngMnA9Q28/1LgNqAPsA74aXPbmll/4G/ATcF2VwPjmrsjZpYGzABeArKAG4DpZjYiaPIEcI27dweO\nAWYHy28CVgXvOQj4cXO3LZ2HAl06snfd/R/uXuHu+9z9Y3ef6+5l7r4KeBQ4vYH3P+vuOe5eCvwJ\nOK4Fbc8F5rv7C8G6+4HtLdiXU4A04JfuXhp0L70MXBKsLwVGmVl3d9/p7p9UWT4IONjdS9xdZ+hS\nLwW6dGTrq86Y2RFm9pKZbTGzfOAuEmfN9dlSZboQ6FZfwwbaDqpahydGEWxoQu01DQLWefVRCGuB\nwcH0hcD5wDozm2VmJwTL7w3avWlmK83sphZsWzoJBbp0ZDWHYD0CLAJGuHsP4HbA2riGzcCQ/TNm\nZnwZws2xCRgavH+/g4GNAMFfHucD/Ul0zfw1WJ7v7je4ezbwdeCHZtbQXyXSiSnQJUq6A3nAXjP7\nCg33n7eWGcDxZnaemaWQ6MPPauQ9cTPLqPJKB94ncQ3gRjNLNbMzgCkk+tEzzexSM+sRdOvsASoA\ngu0OD34R5JEY2lnRNrsqUadAlyi5EbiCROA9QuJCaZty963AvwL3ATuA4cCnJMbN1+cyYF+V1zJ3\nLwbOAy4g0Qf/IHCpu38RvOcKYG3QlXRN8BkAhwNvAQXAe8AD7v5Oq+2gJBV9sUikGcwsTqL75CIF\nq3Q0OkMXaYSZTTazXkHXyW0kRp58FHJZIrUo0EUadyqJseC5wCTgwqALRaRDUZeLiEiS0Bm6iEiS\nCO3mXP369fPs7OywNi8iEknz5s3b7u51Dp0NLdCzs7PJyckJa/MiIpFkZmvrW6cuFxGRJKFAFxFJ\nEgp0EZEkoUAXEUkSCnQRkSShQBcRSRIKdBGRJBG5QF+6JZ9fvLKUvMLSsEsREelQIhfo63YU8vCs\nlazbWRh2KSIiHUrkAn1Qr0wANu7eF3IlIiIdS+QCvX+PdABy9xSFXImISMcSuUDPSI0DUFymxyqK\niFQVuUBPT0mUrEAXEakucoGeFlegi4jUJXKBbmakxWOUKNBFRKppcqCbWdzMPjWzGXWsSzez6Wa2\nwszmmll2axZZUzxmlFco0EVEqmrOGfr3gSX1rLsG2OXuI4D7gZ8faGENSQR6W25BRCR6mhToZjYE\nOAd4rJ4mFwBPBtPPAmeamR14eXWLGVTo4dYiItU09Qz9N8DNQH3nxYOB9QDuXgbkAX1rNjKz68ws\nx8xycnNzW1BuQuIMXYEuIlJVo4FuZucC29x93oFuzN0fdfex7j42K6vOZ5w2STxmlOsMXUSkmqac\noZ8CnG9ma4C/AmeY2R9rtNkIDAUwsxSgJ7CjFeusJmZGhc7QRUSqaTTQ3f0Wdx/i7tnAJcBb7n5Z\njWYvAlcE0xcFbdoscWOmLhcRkZpSWvpGM7sLyHH3F4HHgafNbAWwk0Twtxl1uYiI1NasQHf3WcCs\nYPr2KsuLgItbs7CGxGKgPBcRqS5y3xQFiKvLRUSklkgGekxdLiIitUQy0OMa5SIiUks0A11fLBIR\nqSWSgR4z01f/RURqiGSg6wxdRKS2SAZ64qJo2FWIiHQskQz0uKGLoiIiNUQz0NXlIiJSSyQDPWYa\nhy4iUlMkAz0e0zh0EZGaIhvoOkMXEakukoGu+6GLiNQWyUDXGbqISG2RDPTEAy7CrkJEpGOJZKDH\nYxqHLiJSU0QDXV0uIiI1RTLQdVFURKS2SAa6ztBFRGqLZqDrEXQiIrVEMtBj+qaoiEgtkQz0uO7l\nIiJSSyQDPRbTOHQRkZoiGejxGHoEnYhIDdEMdF0UFRGpJZKBrouiIiK1NRroZpZhZh+Z2QIzW2xm\nd9bR5kozyzWz+cHr2rYpN0EXRUVEaktpQpti4Ax3LzCzVOBdM3vZ3T+s0W66u3+n9UusTY+gExGp\nrdFAd3cHCoLZ1OAVaprGYqaLoiIiNTSpD93M4mY2H9gGvO7uc+to9g0zW2hmz5rZ0Ho+5zozyzGz\nnNzc3BYXrYuiIiK1NSnQ3b3c3Y8DhgDjzOyoGk3+AWS7+zHA68CT9XzOo+4+1t3HZmVltbzomFHh\n4DpLFxGp1KxRLu6+G3gbmFxj+Q53Lw5mHwPGtE55dYubAaCTdBGRLzVllEuWmfUKpjOBs4GlNdoM\nrDJ7PrCkNYusKR5UrW4XEZEvNWWUy0DgSTOLk/gF8Dd3n2FmdwE57v4i8D0zOx8oA3YCV7ZVwQBW\neYauQBcR2a8po1wWAqPrWH57lelbgFtat7T6xWMKdBGRmiL5TdH9fejqchER+VIkAz22/wxdd1wU\nEakUyUCPJ/JcX/8XEakimoEeU5eLiEhNkQz0mC6KiojUEslA10VREZHaIhnoMXW5iIjUEslAj+uL\nRSIitUQz0HWGLiJSSyQDvbisHICScg1EFxHZL5KBvnBDHgCLN+aHXImISMcRyUA/79hBABzUMyPk\nSkREOo5IBnqXtDgAhSXlIVciItJxRDrQN+4qDLkSEZGOI5KB3iMzFYDXl2wNuRIRkY4jkoHev3ui\n7/yIg3qEXImISMcRyUAHGNwrk9w9xY03FBHpJCIb6Bt37+PFBZvCLkNEpMOIbKDvN3t5btgliIh0\nCJEP9Ct+/1HYJYiIdAiRDfQfn/OVyunH3lkVYiUiIh1DZAP9ypOzK6fvfmkJJWW6r4uIdG6RDfSU\nePXSv/3HeSFVIiLSMUQ20AGuPXVY5fSbS7eFWImISPgiHehTJx1ebd71wAsR6cQiHegZqXFW3jOl\ncv4nLy4OsRoRkXA1GuhmlmFmH5nZAjNbbGZ31tEm3cymm9kKM5trZtltUWxd9j+9CODJD9a212ZF\nRDqcppyhFwNnuPuxwHHAZDM7sUaba4Bd7j4CuB/4eeuW2bAzjujfnpsTEemQGg10TygIZlODV83O\n6guAJ4PpZ4EzzcxoJ49+c0x7bUpEpMNqUh+6mcXNbD6wDXjd3efWaDIYWA/g7mVAHtC3js+5zsxy\nzCwnN7f1vrJfdQjjsi17Wu1zRUSipEmB7u7l7n4cMAQYZ2ZHtWRj7v6ou49197FZWVkt+YhGrdup\nh16ISOfUrFEu7r4beBuYXGPVRmAogJmlAD2BHa1RYFP165YGwNxV7bpZEZEOoymjXLLMrFcwnQmc\nDSyt0exF4Ipg+iLgLW/nQeH/fsIhADz27ur23KyISIfRlDP0gcDbZrYQ+JhEH/oMM7vLzM4P2jwO\n9DWzFcAPgGltU279Lhw9uL03KSLSoaQ01sDdFwKj61h+e5XpIuDi1i2teQ7p2yXMzYuIhC7S3xSt\nqh1HSYqIdEhJE+giIp1dUgb6qtyCxhuJiCSZpAz0LXlFYZcgItLukirQLx4zBICbn1sYciUiIu0v\nqQL95BGJuw1szdcZuoh0PkkV6F89PHHXxatPGdZISxGR5JNUgZ6RGgfgkTmrQq5ERKT9JVWgp6ck\n1e6IiDRLUiWgvlwkIp1ZUgW6iEhnpkAXEUkSSRvom/P2hV2CiEi7SrpA75qWGOnykxcXh1yJiEj7\nSrpAP6hnBgCvLt4aciUiIu0r6QL9x+eMCrsEEZFQJF2gTzg88fDpoX0yQ65ERKR9JV2gmxlDemcy\nsn/3sEsREWlXjT6CLoo27NrHhl0a5SIinUvSnaFX5e5hlyAi0m6SOtCf/2Rj2CWIiLSbpA70G59Z\nEHYJIiLtJikD/Xtnjgy7BBGRdpeUgX704J5hlyAi0u6SMtDPHjWgcnrRxrwQKxERaT+NBrqZDTWz\nt83sczNbbGbfr6PNBDPLM7P5wev2tim3+c5/6N2wSxARaRdNGYdeBtzo7p+YWXdgnpm97u6f12j3\njruf2/olHpgKjVwUkU6i0TN0d9/s7p8E03uAJcDgti5MRESap1l96GaWDYwG5tax+iQzW2BmL5vZ\nka1Q2wFZcPvEyunCkrIQKxERaR9NDnQz6wY8B/ynu+fXWP0JcIi7Hwv8N/D3ej7jOjPLMbOc3Nzc\nltbcJD27pFZOT3vuszbdlohIR9CkQDezVBJh/id3f77menfPd/eCYHomkGpm/epo96i7j3X3sVlZ\nWQdYetO9uGBTu21LRCQsTRnlYsDjwBJ3v6+eNgcF7TCzccHn7mjNQlvi+IN7VU7rvi4ikuyacoZ+\nCvBN4IwqwxKnmNm3zOxbQZuLgEVmtgB4ELjEO0CCPnHluMrpq//wcYiViIi0vUaHLbr7u4A10uYh\n4KHWKqq1dM/4cvfeXta2ffYiImFLym+K7heLGb+86JjK+Yv+9/0QqxERaVtJHegAF40ZUjmds3ZX\niJWIiLStpA/04FptpexpL7GnqDSkakRE2k7SBzrArKkTqs0v31oQTiEiIm2oUwR6dr+u1ea/ob50\nEUlCnSLQAV67YXy1+ekfrwupEhGRttFpAv2wAd2rzf/wuc/IWbMzpGpERFpfpwl0gF9dfGy1+Ydn\nrQypEhGR1tepAv3C0dXv+vvW0m3c9vdFIVUjItK6OlWgx2NW6yz96Q/XsnzrnpAqEhFpPZ0q0CHx\nRaM7zhtVbdnE++eQr7HpIhJxnS7QAa46ZVitZcf85DXdZldEIq1TBjrAU1ePq7Xse3/5NIRKRERa\nR6cN9PGHZfHby8bUWr63WI+rE5Fo6rSBDjD5qINqLTvyjlfZtbckhGpERA5Mpw50gFX3TKm1bPRP\nX+eYn7yqh0uLSKR0+kCPxYy7v35UreX5RWXMX787hIpERFqm0wc6wGUnHlLn8kt/N5c3Pt/aztWI\niLSMAj2w+r+m8I3jh9Rafu1TOWRPe4lP1+3Sg6ZFpENToAfMjF//y7Gs/q/afeoAFz78PlfpQdMi\n0oEp0Guo+YSjqmYty+XBN79ox2pERJpOgV6HxXdOIiO17h/Nfa8vZ9Ttr3Dj3xaoC0ZEOhQFeh26\npqew+M7JvHPzV+tcX1hSznOfbGDYLTOZtWwbm/P2tXOFIiK1WVhnmWPHjvWcnJxQtt0cH67aweJN\n+fx0xucNtnviqn+isLicc44Z2E6ViUhnZGbz3H1sXetS2ruYqDnx0L6ceGhfJo4awGm/eLvedlc9\nkbhgetiA8Yys8XQkEZH2oC6XJhrapwsL7pjI984c2WC7s++fw32vLaO0vKKdKhMRSWi0y8XMhgJP\nAQMABx519wdqtDHgAWAKUAhc6e6fNPS5UelyqWlbfhHj7nmzWe9Z+tPJZKTG26giEelMGupyaUqg\nDwQGuvsnZtYdmAd83d0/r9JmCvBdEoF+AvCAu5/Q0OdGNdAB8otK2ZZfzB/eX80fP1zX5Pe9dsP4\nWg+rFhFpjoYCvdEuF3ffvP9s2933AEuAwTWaXQA85QkfAr2CXwRJqUdGKiP6d+Ou84/io1vPbPL7\nJt4/h+KycioqNNxRRFpfs/rQzSwbGA3MrbFqMLC+yvwGaoc+ZnadmeWYWU5ubm7zKu2AYjGjf48M\nZnz3VK6u4ylIdTn8x69w6K0zWbwpj+xpL/HLV5eyo6CYJ99fo3HtInJAmjxs0cy6AbOBn7n78zXW\nzQDudfd3g/k3gR+6e719KlHucqlPYUkZZ983h427WzYu/fKTDuGuC2rf+VFEZL8D6nIJPiAVeA74\nU80wD2wEhlaZHxIs61S6pKXw3rQzGNI7s0Xvf+qDtWRPe4nsaS9x7ZM5bNy9jxfmb2SBbuMrIk3Q\n6Dj0YATL48ASd7+vnmYvAt8xs7+SuCia5+6bW6/MaHl76gQq3ElPibN0Sz6Tf/NOsz/jjSVbeWPJ\nl7fuXfGzr5ES1yhTEalfU0a5nAq8A3wG7B9cfStwMIC7/zYI/YeAySSGLV7VUHcLJGeXS2N+9tLn\n/O6d1a3yWUP7ZHLEQT2471+OpXtGaqt8poh0fAc0bLGtdMZAB9i0ex9zV+/ghukLWvVzZ37vNAb3\nziQlZnRN1xeARZKVAr0DO/onr7KnqHWfXXr2qAH87vKx7NpbQkrc6J6RSll5BWZGPFb/7YFFpONT\noEfAMznryS8q477XlrG3pPyAP+/4g3vxybrExdRbpxzBPTOXMmpgD2Z+/7QD/mwRCY8CPWK25RdR\nXFbB0D5dyJ72Uqt+9qQjB3D5SdkM7pXJpb/7kIcvG8NxQ3u16jZEpO0o0CNs/c5Cdu4tIWbGeQ+9\n26bbmjrxML5zRsM3HxORcCnQk0hJWQUfrNrBrr0l/Of0+a3++Wbw7g/PoFtaClv3FNW690xRaTlH\n3PYK0752BN86fXirb19EGqb7oSeRtJQYpx+WBUDunmJ+NnMJ79z8VXYVlnD+Q+8d8Oe7wyn3vlU5\nP2vqBIb0zmTGws2MOaQ3uwtLAbj35aWcd+wgBvdq2ZeoRKT16Qw9iZSUVfD+yu0Mz+rGhQ+/z/aC\n4jbf5qp7phDTyBmRdqMul07I3Xl18VYOP6g7w/p1ZdfeEkb/9PU22da3Th/O2h17uefCo+ndNQ2A\nDbsKWZW7l/HBXxMi0joU6ALAo3NWcs/MpW26jQtHD6ZXl1SeeG8NAEvumkxmWpyy8grdukCkFSjQ\npZpde0vo1SUVM2NLXhHn/ve7bdo9c9Khfflg1Q7GH5bFP48ezOzluUyddDi7C0s4clDPNtuuSDJS\noEuD8gpLeXjWCn4w8TAKisro2y2dD1ft4JJHP2yX7R8zpCd//n8n0k23LBBplAJdWmTO8lwu//1H\nTJ14GAN7ZnLjM617/5n63HHeKOau2snFY4dw5lcG1FpfVl7B2p2FDM/q1i71iHQkCnRpNY/OWckz\nORv4YltBu23z7akTOKhHBmt37uWZnA0Ul5Xzxw/X8eTV4+iWnsKYQ3q3Wy0iYVOgS6s77RdvsX7n\nPub9+CxiZnz3L5/y7ortodQya+oEfvnaMuav281rN4ynrMLpmZm4pfCWvCIG9EgncYdnkehToEur\n25pfxIL1u5l45EHVlpeVV7Ait4DM1DiDemUy8kcvh1LfkrsmszlvH2f8ejbfPPEQjhnSk4vGDCF3\nTzEfrdnJuccMCqUukQOlQJfQ/OrVZTz09grOHjWA8SP7cdsLi8MuCYDZN03g9F/O4s/XnsDJI/pV\nLnd3cguK6d89I8TqROqnQJfQFJeV88Knm7h47JDKbo/CkjL++tF6tu4p4uIxQzjrvjmh1TduWB/+\ndv1JQGI45z0zl/DMvA28fsN4Rg7oTnFZOXEzyiqcotJyenVJC61WEVCgSweXV1hKbkExw7O6snZH\nIRN+NQuAwb0y2bh7X7vUMLBnBpvziqotS40bpeXOuGF92FdSzmcb81h+99coLisnLSXGc/M28q//\nNFQPDZF2pUCXyMorLGXD7kI+WbebDTsLeWTOqrBLqmXNveewo6CYFdsKKCguqxxqedvfF9EjM4Wb\nJh0RcoWSTBTokjT2lZTzldtfCbuMBq259xyAyoeTrLn3HCoqnG17ijmop/rm5cDo9rmSNDLT4jx0\n6WhiZnRLT2FE/26kp8Qor3DW7SwkLSVGSizGlAffCa3G7GkvVRsbP/k3c9i4ex97isronpHCff9y\nHKlxY8Lh/UOrUZKTztAlKc1fv5tBPTPo3yODNz7fyhEDu7O9oISfvLiY+et3h11epTd+cDoH9+lC\natyqjZWf+dlmumekcNpI3a1SqlOXi0gN63YUMv6Xb4ddRp26pMUpDB4UPunIAby6eCvL7p5Mekqc\nLXlFdMtIqXbfm+Vb9zAiq5vuS99JKNBFanB3fv3ack4e3heASx+byy8uOoa8wlJ+NnNJyNU17uTh\nfXGHCYdn8V8vL2V4Vlf+cNU4BvfKpLSigpgZqU28XfGWvCL17UeIAl2kGQpLyti+p4RP1u1i3tpd\nzFq+rfI2B/9YsImfv7KMfaXlYZfZqM/vmsSKbQUcM6RXvW1emL+R7/91PtOvO5ETDu3bjtVJSynQ\nRQ5ARYVTWFpe6/a++//feeeL7dz87EK25BfV9fYO4cRD+3D04J6cflh/Pt+cx3FDe/PuF7nM35DH\nnOW5dE2Ls+jOSSzYkEdW93Q9K7YDO6BAN7PfA+cC29z9qDrWTwBeAFYHi55397saK0qBLslk194S\nnv90I18/bhDf+uM87rnwaGYs3Mz89bs5ZURfXvpsCws60MXYunRPT2FPcRmQ6MrZll/MTZMO56tH\n9Ke0vIK9xWWV35TdubeElLjRIyNxE7St+UUM6KFum/ZwoIE+HigAnmog0Ke6+7nNKUqBLp2JuzPs\nlpkA3DTpcM76ygAKiku55skcdheW0jUtTna/rizelB9ypQ3rlp5CQRD6AG/deDpn/Ho2AH++9gSO\nP6Q3uXuKGdqnCyu27WFYv276Jm0rO6Bx6O4+x8yyW7sokc7EzPj4R2fRMzOVtJQvL1bOv31irbZ3\nvLCIJz9YC8A/jx7M859ubLc6G1M1zIHKMAdYtCmPqc8sYFNeETGDiuBc8YFLjuOC4wa3Z5mdVpP6\n0INAn9HAGfpzwAZgE4mz9TpvqWdm1wHXARx88MFj1q5d29K6RTqND1buYNPufTw7bwMfrNoRdjkt\ndtTgHqzO3cv060+qHFWTt6+UtHiMIb0z+fHfF3HRmCGMPjjxpay9xWV01WMJazngi6KNBHoPoMLd\nC8xsCvCAu49s7DPV5SLSPOUVzvBbZzJ14mGce8wg0lJiTP94PR+v2cnT15zAmb+exSkj+nHNqcPI\n21fKhQ+/H3bJTXbWV/rzxpJtQCL4v3vGSK5/eh4AOT8+i37d0vlsQx5HDurBUx+soV/39Abvab9x\n9z76dEkjMy3eHuW3qzYN9DrargHGunuDj69RoIu0rXe/2M7tLy5i9NDeHD24B1ecnI2ZVd5jJkp6\nZKSQX1S9u+eF/38Klzz6Ie/88Kvc8cJiThvZj0vGHQwkbr9waL+uvDV1AitzC5i9LJerTx1W63OX\nbdnDiP7R6udv03u5mNlBwFZ3dzMbB8SA6P5dKJIkTh3Zj7dunFBr+dxbz2TDrn2MOaQ3by3dytV/\nSJxYrbn3HN5fsZ1LH5vbzpU2rmaYA1zwP+8BMPbuNwB46bPNLN6Uz3FDE+PuV23fy7y1O7nyiY/Z\nU1TG+MP60SMjlV5d0khLibFi2x4m/WYO/zFhODdPPoKi0nIyUqN9Rt+UUS5/ASYA/YCtwB1AKoC7\n/9bMvgN8GygD9gE/cPdG/9bTGbpIx+Du1e4j88R7q7nzH59Xzp94aB8+XLWzcv760w/lkdkd7zbG\nzfHvJxzMn+auq5yfOvEwfvXach78t9GMGtid2cu3c02VM/rcPcUAZHVPb/daa9IXi0SkWXbtLSE9\nNcbe4nJ6Zqbyybpd/Hb2Sn5/xT9V3jOmuKycFdsKuPX5z1iwIQ+A73x1BA+9vYLhWV1Zmbs3zF04\nYCP7d6N/j3SevvoEDr01MeR0/62R1+7YS99u6VS4kxaPteuZvQJdRNqMu7M1P3Gvd3enwiFmVI67\nP21kP975ou5LahNHDWBLfhELg18IHd0NZx3G/W8sr7bs8AHdueLkbNJSYlw0Zkib16BAF5F29+e5\n6xg3rA89M1MZd88bXD9+OH27pjHxyAEUl1XwyOxV/PwbR5NS4yZiVb+EFTXPfftkfv7KUj5avZNR\nA3vw9dGDuPykbEbf9Tr7SssZ0b8b+0rKmfa1Izjv2PpH6TREgS4ikVJSVsHW/CL6dkujS1pK5ZOq\nRvbvxjdPOoTbX6jzqy6R0SUtzud3TW7Re/XEIhGJlLSUGEP7dKmcz0yL8+ltZ9MjM5V4zLj8pGze\nW7Gdrukp/P3TjSzZnM/c1YkLt327prFjb0lYpTfJ/vvdtzYFuohEQu+uadXmTxnRD6BymGJVK7YV\nMDyrK6XlzmPvruIXryyr1eb1G8azcEMeA3pkcNnjHW+oZkuoy0VEOr2de0v44XML6dctjevGD+ey\nx+aycfe+Nt3m/hEzzaUuFxGRBvTpmsbvLv8yI9+aejrz1u7i5OH9KpdF4Ru2TXtGlYhIJ5KeEq8W\n5gCPX5EI/HOOHgjA/f96LABPXzOOj350JgBXnpzN3FvP5JghPbn0hIPr/fxPbju7LcpWl4uISFNt\n21NE/+4Z7C4sqXzYR0PKK5ztBcUUFJdx5q9nc9rIfvzu8rEH9EUkdbmIiLSC/t0Tt/1tSpgDxGPG\ngB4ZDKDlfebNoS4XEZEkoUAXEUkSCnQRkSShQBcRSRIKdBGRJKFAFxFJEgp0EZEkoUAXEUkSoX1T\n1MxygbUtfHs/oO5HoCQv7XPnoH3uHA5knw9x96y6VoQW6AfCzHLq++prstI+dw7a586hrfZZXS4i\nIklCgS4ikiSiGuiPhl1ACLTPnYP2uXNok32OZB+6iIjUFtUzdBERqUGBLiKSJCIX6GY22cyWmdkK\nM5sWdj0tZWZDzextM/vczBab2feD5X3M7HUz+yL4b+9guZnZg8F+LzSz46t81hVB+y/M7Iqw9qmp\nzCxuZp+a2YxgfpiZzQ32bbqZpQXL04P5FcH67CqfcUuwfJmZTQpnT5rGzHqZ2bNmttTMlpjZScl+\nnM3shuDf9SIz+4uZZSTbcXhVgzsAAAPCSURBVDaz35vZNjNbVGVZqx1XMxtjZp8F73nQzKzRotw9\nMi8gDqwEDgXSgAXAqLDrauG+DASOD6a7A8uBUcAvgGnB8mnAz4PpKcDLgAEnAnOD5X2AVcF/ewfT\nvcPev0b2/QfAn4EZwfzfgEuC6d8C3w6m/wP4bTB9CTA9mB4VHPt0YFjwbyIe9n41sL9PAtcG02lA\nr2Q+zsBgYDWQWeX4XplsxxkYDxwPLKqyrNWOK/BR0NaC936t0ZrC/qE08wd4EvBqlflbgFvCrquV\n9u0F4GxgGTAwWDYQWBZMPwL8W5X2y4L1/wY8UmV5tXYd7QUMAd4EzgBmBP9YtwMpNY8x8CpwUjCd\nErSzmse9aruO9gJ6BuFmNZYn7XEOAn19EFIpwXGelIzHGciuEeitclyDdUurLK/Wrr5X1Lpc9v9D\n2W9DsCzSgj8xRwNzgQHuvjlYtQUYEEzXt+9R+5n8BrgZqAjm+wK73b0smK9af+W+BevzgvZR2udh\nQC7wRNDN9JiZdSWJj7O7bwR+BawDNpM4bvNI7uO8X2sd18HBdM3lDYpaoCcdM+sGPAf8p7vnV13n\niV/NSTOu1MzOBba5+7ywa2lHKST+LP9fdx8N7CXxp3ilJDzOvYELSPwyGwR0BSaHWlQIwjiuUQv0\njcDQKvNDgmWRZGapJML8T+7+fLB4q5kNDNYPBLYFy+vb9yj9TE4BzjezNcBfSXS7PAD0MrOUoE3V\n+iv3LVjfE9hBtPZ5A7DB3ecG88+SCPhkPs5nAavdPdfdS4HnSRz7ZD7O+7XWcd0YTNdc3qCoBfrH\nwMjgankaiQsoL4ZcU4sEV6wfB5a4+31VVr0I7L/SfQWJvvX9yy8PrpafCOQFf9q9Ckw0s97BmdHE\nYFmH4+63uPsQd88mcezecvd/B94GLgqa1dzn/T+Li4L2Hiy/JBgdMQwYSeICUofj7luA9WZ2eLDo\nTOBzkvg4k+hqOdHMugT/zvfvc9Ie5ypa5bgG6/LN7MTgZ3h5lc+qX9gXFVpwEWIKiREhK4EfhV3P\nAezHqST+HFsIzA9eU0j0Hb4JfAG8AfQJ2hvwP8F+fwaMrfJZVwMrgtdVYe9bE/d/Al+OcjmUxP+o\nK4BngPRgeUYwvyJYf2iV9/8o+FksowlX/0Pe1+OAnOBY/53EaIakPs7AncBSYBHwNImRKkl1nIG/\nkLhGUEriL7FrWvO4AmODn99K4CFqXFiv66Wv/ouIJImodbmIiEg9FOgiIklCgS4ikiQU6CIiSUKB\nLiKSJBToIiJJQoEuIpIk/g/NFPg3qgiV4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCsDapUTBBrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNN.save(current_path + \"models/text_generator_RNN_00.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrMdonRckAWB",
        "colab_type": "text"
      },
      "source": [
        "# Text Generation\n",
        "\n",
        "At this point, let's check how the model generates text. In order to do it, I must make some changes to my RNN architecture above.\n",
        "\n",
        "First, I must change the fixed batch size. After training, I want to feed just one sentence into my Network to make it continue the character sequence. I will feed a string into the model, make it predict the next character, update the input sequence, and repeat the process until a long generated text is obtained. Because of this, the succession of input sequences is now different from training session, in which portions of text were sampled randomly. I now have to set `stateufl = True` in the `LSTM()` layer, so that each LSTM cell will keep in memory the internal state from the previous sequence. With this I hope the model will better remember sequential information while generating text.\n",
        "\n",
        "I will instantiate a new `generator` RNN with these new features, and transfer the trained weights of my `RNN` into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69aV7FGVAtxY",
        "colab_type": "code",
        "outputId": "87c106a7-f0cf-4bf4-8507-13551f88d290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "generator = Sequential([\n",
        "    Embedding(vocab_size, embedding_size,\n",
        "              batch_input_shape=(1, None)),\n",
        "    \n",
        "    LSTM(len_input, return_sequences = True, stateful=True),\n",
        "    \n",
        "    Dense(hidden_size, activation = relu), \n",
        "    \n",
        "    Dense(vocab_size)\n",
        "])\n",
        "\n",
        "generator.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 250)            15750     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (1, None, 1000)           5004000   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 250)            250250    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 63)             15813     \n",
            "=================================================================\n",
            "Total params: 5,285,813\n",
            "Trainable params: 5,285,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whB1azhVAtrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import trained weights from RNN to generator\n",
        "generator.set_weights(RNN.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE2hYSqAAtkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(start_string, num_generate = 1000, temperature = 1.0):\n",
        "    \n",
        "    # Vectorize input string\n",
        "    input_eval = [char2idx[s] for s in start_string]  \n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    \n",
        "    text_generated = [] # List to append predicted chars \n",
        "    \n",
        "    idx2char = { v: k for k, v in char2idx.items() }  # invert char-index mapping\n",
        "    \n",
        "    generator.reset_states()\n",
        "    \n",
        "    for i in range(num_generate):\n",
        "        predictions = generator(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        \n",
        "        # sample next char based on distribution and temperature\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        \n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "        \n",
        "    return (start_string + ''.join(text_generated))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hBCF5YrqBtG",
        "colab_type": "text"
      },
      "source": [
        "(This function is based on [this tutorial](https://www.tensorflow.org/tutorials/text/text_generation).)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_NWeo1fAtiC",
        "colab_type": "code",
        "outputId": "b41dd336-8c12-4b44-d889-0a7de1c97af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Let's feed the first lines:\n",
        "start_string = \"\"\"\n",
        "Nel mezzo del cammin di nostra vita\n",
        "mi ritrovai per una selva oscura,\n",
        "chè la diritta via era smarrita.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for t in [0.1, 0.5, 1.0, 1.5, 2]:\n",
        "    print(\"####### TEXT GENERATION - temperature = {}\\n\".format(t))\n",
        "    print(generate_text(start_string = start_string, num_generate = 1000, temperature = 1.0))\n",
        "    print(\"\\n\\n\\n\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "####### TEXT GENERATION - temperature = 0.1\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita.\n",
            "\n",
            "E fui dentro li palmi in su lo diso,\n",
            "e più di senti a la tigurar lormi,\n",
            "puosi e perde, scendero posa è ragge,\n",
            "di settare in foce lo dispettorio:\n",
            "\n",
            "\"se buatti fanti mal vita ricorse\n",
            "del tul, sani, 'de da nostrin molte\n",
            "che giattimenza, nona personazise;\n",
            "crovente Perrai pieghi e dicerno lascio,\n",
            "\n",
            "e la seco del condier da sè spirti;\n",
            "poi rimasesti 'ntender'obbi frati,\n",
            "sanza medesse, da sapir più segue.\n",
            "\n",
            "Oh su per dal mondo è disse: \"E come il nove,\n",
            "nel mi ragga da Parla una uscisci\n",
            "dove s'appossar riguardando vidi,\n",
            "onde piante paia\", mi disse, \"pertegno\n",
            "regnida qui tolvede avea bena\".\n",
            "\n",
            "Animmi ciò ud'amici acceroperi,\n",
            "se non la templa\".\n",
            "E quell'anime che tu diudo:\n",
            "voglia vòlto assai a la gente reva.\n",
            "\n",
            "Ciò precedean perve in unsi scarria,\n",
            "per che gramar precità? Fatti al cui l'otto,\n",
            "villa qua noi e un viso da contalla\n",
            "stesti e centrustalmente sì, perchè parlae?\".\n",
            "\n",
            "Sì cominciai coi bigliullo appresso, come,\n",
            "per si scuserbiarar che non paregno,\n",
            "che piace, duole, avvegna cui arriva\n",
            "dì tra 'l cielo,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "####### TEXT GENERATION - temperature = 0.5\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita.\n",
            "\n",
            "E me ricoffaccio, com'esser possente\n",
            "di letto mi, e gradolar fur c' ha miseri,\n",
            "ch'io dicea, mossi mosser tempo il piede\".\n",
            "\n",
            "Come di qua tuffa: egne declati fui,\n",
            "là mi e disdetti se per le gorine,\n",
            "se bene che posson convenne lui.\n",
            "\n",
            "Con menti persungei o vigliar divini?\n",
            "l'un se' sedei a la vive e latdar del cerci,\n",
            "per lui si raddore a l'altra pressuma\n",
            "la brieta che hai non hanno circavi.\n",
            "\n",
            "Ma poi faggin quei che notte amore,\n",
            "appresso 'l giudo: \"A me care drizzanza,\n",
            "che si conveggea con un letto disto?'.\n",
            "\n",
            "Ed egne a' maeti; e questi sgurti\n",
            "ordenni mani amagion ch'a sordeva\n",
            "io e qual Fiosenti lio dol fiatorno,\n",
            "segria la sua concero ebbe acduse;\n",
            "e l'uno e loca il disio mi ricorda,\n",
            "\n",
            "nè vei da le poco, ancun sette forte,\n",
            "che, come tre, sangue due nomisar che,\n",
            "contrammo ha pensaia sarà sù divolse,\n",
            "\n",
            "tempo chi 'n su la terra si fodile\n",
            "conìte a peccato d'ogna ingegno volte,\n",
            "quando il suo del dritto vonte male gente.\n",
            "\n",
            "Quand'io nel mio corsavo; e quei gravaco\n",
            "di sè di mostro discingelli e atto\n",
            "come suo\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "####### TEXT GENERATION - temperature = 1.0\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita.\n",
            "\n",
            "Vedi mosse rimoe a quel de' piedi;\n",
            "non è concue; volginiò, perchè 'l mio maestro\n",
            "vassisi lubili albalar trattava.\n",
            "\n",
            "Prima che lì già m'esta venea infiolta\n",
            "stialmo partito se giusta e civi\n",
            "che richeramma Paria, ogne gran forte;\n",
            "ma qual è vapore, sì come suo chioto,\n",
            "\n",
            "così ti trevato in che li occhi rammette\n",
            "in alto grazia di Dio esi si spelta;\n",
            "tutto che va così con li valdanti\n",
            "che come fia cotanto rimasero.\n",
            "\n",
            "Era nostra si pade al vasar mirando,\n",
            "in lam, da pria, se, che m'apprende\n",
            "che più cadai co' cuole e di coloro.\n",
            "\n",
            "Ma perchè costui calendo in su la fra\n",
            "d'ella verrani, che non si tristallo\n",
            "el dicer: \"Che 'l ciel che vedea velace\n",
            "vinta va i darchi, e più non sosteggio\".\n",
            "\n",
            "\"O drizzati, fumitando, suoi panni\n",
            "cominciare: \"Voi nulla giù sì pira,\n",
            "non vista zai come non coro riso\n",
            "averse del, sol, che tu se' fu ardi;\n",
            "\n",
            "e se si vostri men viver coro;\n",
            "l'umano mi tesse a quel che sotto\n",
            "da sè porgitin Tabille vermita,\n",
            "di ciasti d'i miracci m'eran maiachi\".\n",
            "\n",
            "Poi ci votra le parole, malignarri,\n",
            "rappiril\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "####### TEXT GENERATION - temperature = 1.5\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita.\n",
            "\n",
            "Lo duca che più sù con avoppa,\n",
            "ch'i' non ravalli ogne sotto morse;\n",
            "\n",
            "nè scescosser non facea sì distese\n",
            "di nostra vasi, e poi e però e ria\n",
            "che corresti volti a li occhi fati queste,\n",
            "bianche' mi a cercar sanz'altrumero breso.\n",
            "\n",
            "Non dispiardi di balga fui senzi sozzo,\n",
            "che è pur come già sen ha ci si foco,\n",
            "lì s'antramente, predòn che rattalle\n",
            "da quei e lea le ciel deggiosi un sotto.\n",
            "\n",
            "\".\n",
            "\n",
            "Verta quelli avegne si ricerda\n",
            "di veri legge spazion poco del,\n",
            "quando sè mi ch'io etando fossi 'l nostro;\n",
            "chè quelli addoro accotti li occhi tosto!\n",
            "\n",
            "Vedi che l'uminal che nel come\n",
            "sidimo apirtà chè qui, mi divessi\n",
            "con essure, io poi vi ingenna impreglio\n",
            "de l'altruile di terzo e terra dime.\n",
            "\n",
            "E io mi parti da Caporadice,\n",
            "che mi parrava, accurandate affetto\n",
            "forte i primi li biammugidò inver' lo guardo\n",
            "come vertè quello argomenta, il brade\n",
            "dove s'attorsi non fusse iltrimenti.\n",
            "\n",
            "E un erano ad esse in creatura\n",
            "lasciò dà l'invilla qual di regi!\n",
            "a, cantando a lui si sonta e non dovesti:\n",
            "mi piave di veresseri due rig\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "####### TEXT GENERATION - temperature = 2\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "chè la diritta via era smarrita.\n",
            "\n",
            "Quindi si provegna, vista, da la calle\n",
            "di Vinon che tre corce d'esta e 'l geli.\n",
            "\n",
            "O come fracciali, più commando\n",
            "conciuto di pensare o mertava,\n",
            "per gradi di venire, o de la Scorsa\n",
            "del gino ancor che nuvi' son questi chiari,\n",
            "e far calando, e io cadder giuncipi,\n",
            "pria che sè come in te pianer giorno\".\n",
            "\n",
            "E io e potiti disse: \"Frozia,\n",
            "e come fece l'omiglio di tanta?\".\n",
            "\n",
            "Ed ilmi el, converebile\n",
            "lor parli de Dio, appresi lasciuti,\n",
            "boscia quanto la gentù che fassi scorta\n",
            "da sua perstute atarve, e serò volto\".\n",
            "Com'io nel sue spene e m'egel seguita\n",
            "per tutto lor cabi che a tre ciel venti\".\n",
            "\n",
            "Vite stui affaticasi o Terravi,\n",
            "de le sua boggia con io, e dissi me';\n",
            "o destro parlo storneso accidere,\n",
            "faminata dices, che li occhi vieni:\n",
            "per che, sì mi parvere averbali sauri.\n",
            "\n",
            "Lo spirato che mai ne consusciale,\n",
            "e i drugi tiammandi così fardi\".\n",
            "\n",
            "Così si sieva nòmin che meno,\n",
            "che è che s'arscusa da ciel gravigna\n",
            "vio si cima, maestro il grido posso,\n",
            "se tre tre grado verili a Dander lei,\n",
            "e al qual si converrai n\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8KlRGTqmGBS",
        "colab_type": "text"
      },
      "source": [
        "The best generation is, IMHO, the one with `temperature = 1.5`. The sentences of course do not make sense, but it's amazing that such a simple model could achieve similar results, and generate absolutely Dante-esque text with just ~40 minutes of GPU training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtB2gvhimUEs",
        "colab_type": "text"
      },
      "source": [
        "Many things could be done at this point:\n",
        "\n",
        "\n",
        "\n",
        "*   Try fancier architectures, such as seq2seq. (I must say though that stacked RNNs didn't provide better results during prototyping.)\n",
        "*   Try Attention models.\n",
        "*   Longer training.\n",
        "*   Adversarial training.\n",
        "\n",
        "I'll try a lot of these techniques, alone and combined. My goal is to make a model that can learn the amazing structure of syllables and rhymes of the whole Comedy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbXuy2OopudL",
        "colab_type": "text"
      },
      "source": [
        "### Sources\n",
        "\n",
        "The main source I used to learn to implement an RNN text generator is [this tutorial on the official TensorFlow website](https://www.tensorflow.org/tutorials/text/text_generation)."
      ]
    }
  ]
}